{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM+YM4K+X3aEPJFlbwfnJyj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Rock-Paper-Scissors game"],"metadata":{"id":"XcvYViAhhK6Y"}},{"cell_type":"markdown","source":["### Preprocesamiento y carga de datos"],"metadata":{"id":"Hil5MdrcwtC5"}},{"cell_type":"markdown","source":["Comenzaremos dandole los permisos necesarios para que Google Colab puede acceder a Google Drive. Seguidamente, generaremos las rutas pertenecientes a nuestros archivos que se encuentran en el propio Drive."],"metadata":{"id":"H53euet1wRww"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k5dfyXh-vDVj","executionInfo":{"status":"ok","timestamp":1756666757502,"user_tz":-120,"elapsed":1143,"user":{"displayName":"Juan Ramon","userId":"08272446682823668326"}},"outputId":"d20cfd90-a11d-407a-f62e-d4808a6c043e"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["Una vez montado y conectado nuestro notebook y dado los permisos necesarios para acceder a nuestra Unidad de Drive, generaremos las rutas sobre las que trabajaremos."],"metadata":{"id":"wN_mpXHlvYQ4"}},{"cell_type":"code","source":["dataset_path = \"/content/drive/MyDrive/Tarea_final/Dataset\""],"metadata":{"id":"oSgLoJVRvk97"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A continuación, debido al tamaño de nuestro dataset, debemos dividrlo por lotes, puesto que sino sería muy pesado en memoría. Para ello haremos uso de la función *Sequence* de Keras que nos ayudará a controlar la carga de los datos y mejorar el procesamiento de los mismos."],"metadata":{"id":"iG6r1cvYw5As"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.utils import Sequence\n","import cv2\n","import os\n","\n","class RPSSequence(Sequence):\n","    def __init__(self, image_paths, labels, batch_size, target_size=(200, 300)):\n","        self.image_paths = image_paths\n","        self.labels = labels\n","        self.batch_size = batch_size\n","        self.target_size = target_size\n","\n","    def __len__(self):\n","        nLotes = int(np.ceil(len(self.image_paths) / self.batch_size))\n","        print(\"El número de lotes es de: \", nLotes)\n","        return nLotes\n","\n","    def __getitem__(self, idx):\n","        batch_paths = self.image_paths[idx * self.batch_size : (idx+1) * self.batch_size]\n","        batch_labels = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n","\n","        batch_images = []\n","        for path in batch_paths:\n","            img = cv2.imread(path)\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            img = cv2.resize(img, self.target_size)\n","            img = img / 255.0\n","            batch_images.append(img)\n","\n","        return np.array(batch_images), np.array(batch_labels)\n"],"metadata":{"id":"teCIL5pAygyx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Como podemos observar, hemos creado una clase, típica, para manejar la inyección de datos. En un primer lugar hemos definido las propiedades de la clase en el método init. Seguidamente, en el método len estudiamos el número de lotes en los que los dividiremos. Por último, la función getitem da al conjunto de entreamiento un lote cada vez que lo requiera el modelo.\n","\n","A continuación viene el apartado del preprocesamiento. Sin embargo, en nuestra funcióna anterior ya hemos avanzado en este tema con dos pasos.  El primero de ellos ha sido el escalar las imagenes al realizar:\n","```\n","img = img / 255.0  \n","```"],"metadata":{"id":"Or5rWZWKyrZL"}},{"cell_type":"markdown","source":["Con esto pretendemos es acotar el rango ya que como va de [0,255] relentizaría bastante el preprocesamiento, por lo que ahora se movería en un rango de [0,1].\n","\n","Otra acción ha sido la redimensión de las imagenes ya que todos los modelos de DL necesitan de que todas las imagenes reciban el mismo tamaño. Para ello hemos hecho uso de la función:\n","```\n","img = cv2.resize(img, self.target_size)\n","```"],"metadata":{"id":"yEnXZzVy25hU"}},{"cell_type":"markdown","source":["Gracias a estas dos acciones conseguimos uniformidad en el tamaño de las imagenes y normalización.\n","\n","Ahora, podemos dividir el conjunto de datos que lo separaremos en: train (70%), val (20%) y test (10%)."],"metadata":{"id":"1K21m1zh3lHY"}},{"cell_type":"code","source":["import glob\n","from sklearn.model_selection import train_test_split\n","\n","clases = {\"rock\": 0, \"paper\": 1, \"scissors\": 2}\n","\n","image_paths = []\n","labels = []\n","\n","for clase, idx in clases.items():\n","    paths = glob.glob(os.path.join(dataset_path, clase, \"*.png\"))\n","    image_paths.extend(paths)\n","    labels.extend([idx] * len(paths))\n","\n","image_paths = np.array(image_paths)\n","labels = np.array(labels)\n","\n","\n","X_train, X_temp, y_train, y_temp = train_test_split(image_paths, labels, test_size=0.3, stratify=labels, random_state=42)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.33, stratify=y_temp, random_state=42)\n","\n","print(f\"Para el conjunto train (70%) contamos con: {len(X_train)} imagenes.\")\n","print(f\"Para el conjunto val (20%) contamos con: {len(X_val)} imagenes.\")\n","print(f\"Para el conjunto test (10%) contamos con: {len(X_test)} imagenes.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tKKbj0Bl0ZQ_","executionInfo":{"status":"ok","timestamp":1756663385063,"user_tz":-120,"elapsed":4700,"user":{"displayName":"Juan Ramon","userId":"08272446682823668326"}},"outputId":"97674f98-9409-4ad5-ac7b-251523a22903"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Para el conjunto train (70%) contamos con: 1558 imagenes.\n","Para el conjunto val (20%) contamos con: 448 imagenes.\n","Para el conjunto test (10%) contamos con: 221 imagenes.\n"]}]},{"cell_type":"markdown","source":["Una vez dividos los conjuntos haremos uso de la función previamente creada, *class RPSSequence*, para dividir los datos en los lotes anteriomente explicado. En este caso utilizaremos un batch_size de 32 ya que nos aporta menos memoria RAM, nos ayuda a generalizar y es más ruidoso."],"metadata":{"id":"fHnSlYua-QCX"}},{"cell_type":"code","source":["batch_size = 32\n","\n","train_gen = RPSSequence(X_train, y_train, batch_size=batch_size)\n","val_gen = RPSSequence(X_val, y_val, batch_size=batch_size)\n","test_gen = RPSSequence(X_test, y_test, batch_size=batch_size)"],"metadata":{"id":"rUtBqaS6-9R6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Entrenamiento de modelos"],"metadata":{"id":"MbDlQEXoxCjD"}},{"cell_type":"markdown","source":["En esta nueva sección generaremos distintos modelos de DL, con el fin de aproximarnos a aquel que nos arroje los mejores resultados.\n","\n","Crearemos una red nueronal convolucional (CNN), que son las especializadas en el preprocesamiento de imagenes, a partir de la detección de bordes, texturas..."],"metadata":{"id":"B-ef2tC78FWe"}},{"cell_type":"code","source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","\n","model = Sequential([\n","    Conv2D(32, (3,3), activation='relu', input_shape=(200,300,3)),\n","    MaxPooling2D((2,2)),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dense(3, activation='softmax')\n","])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"697HI7pE95BX","executionInfo":{"status":"ok","timestamp":1756663392943,"user_tz":-120,"elapsed":796,"user":{"displayName":"Juan Ramon","userId":"08272446682823668326"}},"outputId":"584fb14e-878e-4ef4-f264-3f9c30923824"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}]},{"cell_type":"markdown","source":["Comenzaremos a desgranar este modelo. En primer lugar le atribuimos kernel de 32 don el fin de detectar patrones. A mayor valor, más aprendizaje pero mayor riesgo de overfitting. Por otro lado, tenemos un tamaño de filto de 3 de alto y ancho, esto es el area de la imagen que observará. Seguidamente hemos propuesto como función de activación la relu y una dimensión de entrada de 200x300px y 3 canales rgb.\n","\n","A continuación en MaxPooling2D reducimos las caracteristicas de la imagen a la mitad, por el (2,2) para su capturación.\n","\n","Por último, declaramos que la red debe tener 128 neuronas y tendrá una salida de 3 grupos, por scissors, paper y rock.\n","\n","Una vez generada esta primera red neuronal, marcamos la función perdida, el optimizador y la métrica."],"metadata":{"id":"ttD8KFKZG9UT"}},{"cell_type":"code","source":["model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])"],"metadata":{"id":"Ydi-h6Q5Js_m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(\n","    train_gen,\n","    validation_data=val_gen,\n","    epochs=5,\n","    batch_size=32\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":537},"id":"BMx1v5lEKYhm","executionInfo":{"status":"error","timestamp":1756411202948,"user_tz":-120,"elapsed":15873,"user":{"displayName":"Juan Ramon","userId":"08272446682823668326"}},"outputId":"dec0940f-bf36-401e-8b07-ff414b3f92c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["El número de lotes es de:  49\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","Epoch 1/5\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.5129 - loss: 4.4529El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2063331188.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    399\u001b[0m                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                     )\n\u001b[0;32m--> 401\u001b[0;31m                 val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m    402\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_evaluating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["Para observar los resultados más correctamente los visualizaremos en la siguiente tabla, y a continuación discutiremos los resultados.\n","\n","| Época | Accuracy (train) | Loss (train) | Accuracy (val) | Loss (val) |\n","|-------|-----------------|--------------|----------------|------------|\n","| 1     | 44 %            | 14.79        | 85 %           | 0.566      |\n","| 2     | 85 %            | 0.47         | 85 %           | 0.486      |\n","| 3     | 88 %            | 0.32         | 88 %           | 0.375      |\n","| 4     | 93 %            | 0.25         | 92 %           | 0.252      |\n","| 5     | 96 %            | 0.12         | 88 %           | 0.389      |\n","\n","\n","En la primera época observamos un mal accuracy y una función perdida alta. Esto es esperable al estar iniciandose.\n","\n","De la segunda a la última época observamos como el accuracy mejora progresivamete, al igual que la función de perdida se aminora. Sin embargo, el accierto en val en la última época disminuye y la función perdida supera a la de la epoca 3. Es por ello que podemos entender que el modelo tiende a sobreajuste, por lo que el modelo empieza a memorizar demasiado el train."],"metadata":{"id":"o9mq3RNR8Djf"}},{"cell_type":"markdown","source":["A continuación realizaremos un ajuste de hiperparametros. Para ello utilizaremos la herramienta **Keras Tuner** la cual sirve para probar combinaciones automáticamente."],"metadata":{"id":"zFQouoHtPTTl"}},{"cell_type":"code","source":["!pip install keras-tuner --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p9U1PHtiiJ5r","executionInfo":{"status":"ok","timestamp":1756408052587,"user_tz":-120,"elapsed":7991,"user":{"displayName":"Juan Ramon","userId":"08272446682823668326"}},"outputId":"7ac654e9-6b76-4a4b-bb8f-6c88aa0f1dc2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import keras_tuner as kt\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","\n","def build_model(hp):\n","    model = Sequential()\n","\n","    model.add(Conv2D(\n","        filters=hp.Choice(\"conv_filters\", values=[32, 64, 128]),\n","        kernel_size=hp.Choice(\"kernel_size\", values=[3,5]),\n","        activation=hp.Choice(\"conv_activation\", [\"relu\", \"tanh\", \"sigmoid\"]),\n","        input_shape=(200,300,3)\n","    ))\n","    model.add(MaxPooling2D((2,2)))\n","\n","    if hp.Boolean(\"use_dropout\"):\n","        model.add(Dropout(rate=0.3))\n","\n","    model.add(Flatten())\n","\n","    model.add(Dense(\n","        units=hp.Choice(\"dense_units\", values=[64, 128, 256]),\n","        activation='relu'\n","    ))\n","\n","    model.add(Dense(3, activation='softmax'))\n","\n","    model.compile(\n","        optimizer=hp.Choice(\"optimizer\", values=[\"adam\", \"sgd\", \"rmsprop\"]),\n","        loss='sparse_categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","\n","    return model\n","\n","tuner = kt.RandomSearch(\n","    build_model,\n","    objective=\"val_accuracy\",\n","    max_trials=5,\n","    directory=\"tuner_results\",\n","    project_name=\"rps\"\n",")\n","\n","tuner.search(train_gen, validation_data=val_gen, epochs=5)\n","\n","best_model = tuner.get_best_models(num_models=1)[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A_hrpay2PoDN","executionInfo":{"status":"ok","timestamp":1756409283036,"user_tz":-120,"elapsed":1226650,"user":{"displayName":"Juan Ramon","userId":"08272446682823668326"}},"outputId":"609dd971-7db2-4eeb-aec1-74cf5e1f5ad9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 5 Complete [00h 02m 37s]\n","val_accuracy: 0.5535714030265808\n","\n","Best val_accuracy So Far: 0.9330357313156128\n","Total elapsed time: 00h 20m 25s\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 8 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]}]},{"cell_type":"markdown","source":["Como podemos observar, el accurcy que capta es del 87%, por lo que es bastante bueno. Ahora veremos cuales son de la función perdida de train, así como en val."],"metadata":{"id":"R6m-nHydZuN6"}},{"cell_type":"code","source":["best_model = tuner.get_best_models(num_models=1)[0]\n","\n","history = best_model.fit(\n","    train_gen,\n","    validation_data=val_gen,\n","    epochs=5\n",")\n","\n","train_loss, train_acc = best_model.evaluate(train_gen, verbose=0)\n","val_loss, val_acc = best_model.evaluate(val_gen, verbose=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WNWFR0b7Z_F6","executionInfo":{"status":"ok","timestamp":1755712697552,"user_tz":-120,"elapsed":120467,"user":{"displayName":"Juan Ramon","userId":"08272446682823668326"}},"outputId":"be94c851-ec42-40d4-e5ac-86f437af57e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["El número de lotes es de:  49\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","Epoch 1/5\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - accuracy: 0.7746 - loss: 1.2133El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 464ms/step - accuracy: 0.7759 - loss: 1.2027 - val_accuracy: 0.8951 - val_loss: 0.3784\n","Epoch 2/5\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.8835 - loss: 0.3409El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 363ms/step - accuracy: 0.8836 - loss: 0.3406 - val_accuracy: 0.8996 - val_loss: 0.3588\n","Epoch 3/5\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.9240 - loss: 0.2598El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 356ms/step - accuracy: 0.9240 - loss: 0.2596 - val_accuracy: 0.7522 - val_loss: 0.7414\n","Epoch 4/5\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.9037 - loss: 0.2999El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 376ms/step - accuracy: 0.9037 - loss: 0.3000 - val_accuracy: 0.9174 - val_loss: 0.2668\n","Epoch 5/5\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.9352 - loss: 0.1915El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 358ms/step - accuracy: 0.9353 - loss: 0.1912 - val_accuracy: 0.9152 - val_loss: 0.2745\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n"]}]},{"cell_type":"markdown","source":["El resultado, ya con los hiperparametros ajustados es:\n","\n","| Epoch | Train Accuracy | Train Loss | Val Accuracy | Val Loss |\n","|-------|----------------|-----------|--------------|----------|\n","| 1     | 77%            | 1.2027    | 89%          | 0.3784   |\n","| 2     | 88%            | 0.3406    | 89%          | 0.3588   |\n","| 3     | 92%            | 0.2596    | 75%          | 0.7414   |\n","| 4     | 90%            | 0.3000    | 91%          | 0.2668   |\n","| 5     | 93%            | 0.1912    | 91%          | 0.2745   |\n","\n","\n","Aqui podemos observar que hasta el tercer epoch sube linealmente, para en el cuarto descender levemente y en el quinto y último epochs tener el máximo de trains accuracy. A su vez la función perdidia en train es al más baja. De la misma forma, respecto a val, obtenemos uno de los mejores resultados y aunque no sea la mejor funcion perdida, es igualmente uno de los mejores resultados.\n","\n","A continuación observaremos cuales son los mejores hiperparametros que nos marca Keras Turner."],"metadata":{"id":"QIgkMFU8tN5q"}},{"cell_type":"code","source":["best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n","\n","for param, value in best_hps.values.items():\n","    print(f\"{param}: {value}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-sAMHCzYbJQ","executionInfo":{"status":"ok","timestamp":1756409347475,"user_tz":-120,"elapsed":53,"user":{"displayName":"Juan Ramon","userId":"08272446682823668326"}},"outputId":"23737866-fd7a-4e48-e3b7-84e75c10a7da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["conv_filters: 32\n","kernel_size: 3\n","conv_activation: tanh\n","use_dropout: False\n","dense_units: 128\n","optimizer: rmsprop\n"]}]},{"cell_type":"markdown","source":["Los parámetros que hemos ajustado que componen esta última red neuronal son. En la parte convolucional, se mantienen los 32 filtros y una kernel de 3x3. Sin embargo, la función de activación es la tangente. En la regularización este modelo ha optado por no usar el dropout, a diferencia del anterior, posiblemente por la variabilidad de los mismos. Por último, mencionaremos el optimizador que ha pasado de ser adams a rmsprop, puesto que tiende a ir mejor en problemas de imágenes y secuencias.\n","\n","A continuación, realizaremos técnicas de regularización Lasso, que penaliza los coeficientes absolutos, y Ridge, que se encarga de el cuadrado de los coeficientes. Los evaluaremos independientes con el fin de obtener el mejor resultado."],"metadata":{"id":"bP_p91TT8C7J"}},{"cell_type":"code","source":["from tensorflow.keras import models, layers, optimizers, regularizers\n","\n","def build_model(reg_type=None, l1_val=1e-5, l2_val=1e-4):\n","    if reg_type == \"l1\":\n","        reg = regularizers.l1(l1_val)\n","    elif reg_type == \"l2\":\n","        reg = regularizers.l2(l2_val)\n","    elif reg_type == \"l1_l2\":\n","        reg = regularizers.l1_l2(l1=l1_val, l2=l2_val)\n","    else:\n","        reg = None\n","\n","    model = models.Sequential([\n","        layers.Conv2D(32, (3,3), activation='tanh', input_shape=(200,300,3),\n","                      kernel_regularizer=reg),\n","        layers.MaxPooling2D((2,2)),\n","        layers.Flatten(),\n","        layers.Dense(128, activation='tanh', kernel_regularizer=reg),\n","        layers.Dense(3, activation='softmax')\n","    ])\n","\n","    model.compile(\n","    optimizer=optimizers.RMSprop(),\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n","    )\n","\n","    return model\n","\n","model_original = build_model(reg_type=None)\n","model_l1       = build_model(reg_type=\"l1\")\n","model_l2       = build_model(reg_type=\"l2\")\n","model_l1_l2    = build_model(reg_type=\"l1_l2\")\n","\n","history_original = model_original.fit(\n","    train_gen,\n","    validation_data=val_gen,\n","    epochs=20\n",")\n","\n","history_l1 = model_l1.fit(\n","    train_gen,\n","    validation_data=val_gen,\n","    epochs=20\n",")\n","\n","history_l2 = model_l2.fit(\n","    train_gen,\n","    validation_data=val_gen,\n","    epochs=20\n",")\n","\n","history_l1_l2 = model_l1_l2.fit(\n","    train_gen,\n","    validation_data=val_gen,\n","    epochs=20\n",")\n","\n","results = {\n","    \"Original\": model_original.evaluate(test_gen, verbose=0),\n","    \"L1\": model_l1.evaluate(test_gen, verbose=0),\n","    \"L2\": model_l2.evaluate(test_gen, verbose=0),\n","    \"L1+L2\": model_l1_l2.evaluate(test_gen, verbose=0)\n","}\n","\n","for name, (loss, acc) in results.items():\n","    print(f\"{name} -> Loss: {loss:.4f}, Accuracy: {acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rROiq4KrOlnO","executionInfo":{"status":"ok","timestamp":1756413129650,"user_tz":-120,"elapsed":1501391,"user":{"displayName":"Juan Ramon","userId":"08272446682823668326"}},"outputId":"1b3709b0-0a85-4b1e-b16c-191838f5c637"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["El número de lotes es de:  49\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","Epoch 1/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.3398 - loss: 4.3699El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 380ms/step - accuracy: 0.3400 - loss: 4.3547 - val_accuracy: 0.3549 - val_loss: 1.7569\n","Epoch 2/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.3552 - loss: 1.3419El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 350ms/step - accuracy: 0.3552 - loss: 1.3388 - val_accuracy: 0.3549 - val_loss: 1.0992\n","Epoch 3/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.3353 - loss: 1.1044El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 359ms/step - accuracy: 0.3356 - loss: 1.1044 - val_accuracy: 0.3549 - val_loss: 1.1149\n","Epoch 4/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.3398 - loss: 1.1045El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 354ms/step - accuracy: 0.3395 - loss: 1.1045 - val_accuracy: 0.3549 - val_loss: 1.1035\n","Epoch 5/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.3726 - loss: 1.1036El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 349ms/step - accuracy: 0.3725 - loss: 1.1037 - val_accuracy: 0.3192 - val_loss: 1.1313\n","Epoch 6/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.3273 - loss: 1.1099El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 372ms/step - accuracy: 0.3275 - loss: 1.1098 - val_accuracy: 0.3549 - val_loss: 1.1054\n","Epoch 7/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.3427 - loss: 1.1065El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 371ms/step - accuracy: 0.3426 - loss: 1.1065 - val_accuracy: 0.3549 - val_loss: 1.1045\n","Epoch 8/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.3323 - loss: 1.1067El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 352ms/step - accuracy: 0.3323 - loss: 1.1068 - val_accuracy: 0.3549 - val_loss: 1.1046\n","Epoch 9/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.3372 - loss: 1.1080El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 357ms/step - accuracy: 0.3371 - loss: 1.1080 - val_accuracy: 0.3192 - val_loss: 1.0994\n","Epoch 10/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.3354 - loss: 1.1050El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 339ms/step - accuracy: 0.3354 - loss: 1.1050 - val_accuracy: 0.3549 - val_loss: 1.0982\n","Epoch 11/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.3284 - loss: 1.1104El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 351ms/step - accuracy: 0.3284 - loss: 1.1104 - val_accuracy: 0.3549 - val_loss: 1.0987\n","Epoch 12/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.3248 - loss: 1.1055El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 343ms/step - accuracy: 0.3249 - loss: 1.1056 - val_accuracy: 0.3192 - val_loss: 1.1007\n","Epoch 13/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.3458 - loss: 1.1080El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 351ms/step - accuracy: 0.3458 - loss: 1.1080 - val_accuracy: 0.3259 - val_loss: 1.1003\n","Epoch 14/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.3244 - loss: 1.1048El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 341ms/step - accuracy: 0.3245 - loss: 1.1048 - val_accuracy: 0.3549 - val_loss: 1.0976\n","Epoch 15/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.3228 - loss: 1.1063El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 360ms/step - accuracy: 0.3228 - loss: 1.1063 - val_accuracy: 0.3192 - val_loss: 1.1016\n","Epoch 16/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.3380 - loss: 1.1038El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 350ms/step - accuracy: 0.3379 - loss: 1.1038 - val_accuracy: 0.3549 - val_loss: 1.0988\n","Epoch 17/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.3131 - loss: 1.1086El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 353ms/step - accuracy: 0.3134 - loss: 1.1086 - val_accuracy: 0.3259 - val_loss: 1.1013\n","Epoch 18/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.3264 - loss: 1.1095El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 344ms/step - accuracy: 0.3266 - loss: 1.1095 - val_accuracy: 0.3259 - val_loss: 1.1067\n","Epoch 19/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.3179 - loss: 1.1066El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 353ms/step - accuracy: 0.3178 - loss: 1.1067 - val_accuracy: 0.3549 - val_loss: 1.1037\n","Epoch 20/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.3604 - loss: 1.1016El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 387ms/step - accuracy: 0.3601 - loss: 1.1017 - val_accuracy: 0.3192 - val_loss: 1.1014\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","Epoch 1/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.3202 - loss: 5.9543El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 409ms/step - accuracy: 0.3203 - loss: 5.9356 - val_accuracy: 0.3259 - val_loss: 2.8875\n","Epoch 2/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.3314 - loss: 2.2654El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 354ms/step - accuracy: 0.3314 - loss: 2.2585 - val_accuracy: 0.3259 - val_loss: 1.5721\n","Epoch 3/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.3375 - loss: 1.5075El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 343ms/step - accuracy: 0.3378 - loss: 1.5063 - val_accuracy: 0.3259 - val_loss: 1.4541\n","Epoch 4/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.3385 - loss: 1.3557El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 353ms/step - accuracy: 0.3390 - loss: 1.3559 - val_accuracy: 0.3772 - val_loss: 1.4629\n","Epoch 5/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.4063 - loss: 1.4908El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 341ms/step - accuracy: 0.4078 - loss: 1.4900 - val_accuracy: 0.7254 - val_loss: 1.2115\n","Epoch 6/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.6919 - loss: 1.1874El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 352ms/step - accuracy: 0.6927 - loss: 1.1861 - val_accuracy: 0.7768 - val_loss: 1.0650\n","Epoch 7/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.8110 - loss: 1.0257El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 348ms/step - accuracy: 0.8108 - loss: 1.0258 - val_accuracy: 0.7835 - val_loss: 1.1253\n","Epoch 8/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.7961 - loss: 1.0086El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 348ms/step - accuracy: 0.7962 - loss: 1.0086 - val_accuracy: 0.8214 - val_loss: 1.0187\n","Epoch 9/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.8546 - loss: 0.9169El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 337ms/step - accuracy: 0.8541 - loss: 0.9180 - val_accuracy: 0.8214 - val_loss: 1.0515\n","Epoch 10/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.8132 - loss: 0.9936El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 359ms/step - accuracy: 0.8138 - loss: 0.9925 - val_accuracy: 0.8661 - val_loss: 0.9191\n","Epoch 11/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.8289 - loss: 0.9588El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 332ms/step - accuracy: 0.8288 - loss: 0.9590 - val_accuracy: 0.8661 - val_loss: 0.9157\n","Epoch 12/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.8397 - loss: 0.8930El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 352ms/step - accuracy: 0.8398 - loss: 0.8926 - val_accuracy: 0.8393 - val_loss: 0.9430\n","Epoch 13/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.8835 - loss: 0.8142El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 359ms/step - accuracy: 0.8833 - loss: 0.8145 - val_accuracy: 0.8817 - val_loss: 0.8486\n","Epoch 14/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.8857 - loss: 0.7799El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 352ms/step - accuracy: 0.8859 - loss: 0.7790 - val_accuracy: 0.8906 - val_loss: 0.7888\n","Epoch 15/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.8482 - loss: 0.8908El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 368ms/step - accuracy: 0.8484 - loss: 0.8906 - val_accuracy: 0.8817 - val_loss: 0.7940\n","Epoch 16/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.9034 - loss: 0.7230El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 349ms/step - accuracy: 0.9033 - loss: 0.7232 - val_accuracy: 0.8862 - val_loss: 0.8073\n","Epoch 17/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.9111 - loss: 0.7035El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 349ms/step - accuracy: 0.9111 - loss: 0.7038 - val_accuracy: 0.8750 - val_loss: 0.8219\n","Epoch 18/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.9212 - loss: 0.6403El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 383ms/step - accuracy: 0.9212 - loss: 0.6404 - val_accuracy: 0.8750 - val_loss: 0.7104\n","Epoch 19/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9179 - loss: 0.6395El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 333ms/step - accuracy: 0.9175 - loss: 0.6403 - val_accuracy: 0.8996 - val_loss: 0.7265\n","Epoch 20/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.9270 - loss: 0.5968El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 344ms/step - accuracy: 0.9269 - loss: 0.5970 - val_accuracy: 0.8683 - val_loss: 0.7566\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","Epoch 1/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.3247 - loss: 4.6193El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 394ms/step - accuracy: 0.3247 - loss: 4.6049 - val_accuracy: 0.3259 - val_loss: 1.8462\n","Epoch 2/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.3226 - loss: 1.4303El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 382ms/step - accuracy: 0.3225 - loss: 1.4269 - val_accuracy: 0.3549 - val_loss: 1.1554\n","Epoch 3/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.3535 - loss: 1.1577El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 382ms/step - accuracy: 0.3532 - loss: 1.1576 - val_accuracy: 0.3192 - val_loss: 1.1956\n","Epoch 4/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.3300 - loss: 1.1634El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 334ms/step - accuracy: 0.3300 - loss: 1.1633 - val_accuracy: 0.3192 - val_loss: 1.1492\n","Epoch 5/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.3456 - loss: 1.1535El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 338ms/step - accuracy: 0.3451 - loss: 1.1535 - val_accuracy: 0.3549 - val_loss: 1.1451\n","Epoch 6/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.3554 - loss: 1.1486El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 384ms/step - accuracy: 0.3552 - loss: 1.1486 - val_accuracy: 0.3549 - val_loss: 1.1396\n","Epoch 7/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.3441 - loss: 1.1476El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 352ms/step - accuracy: 0.3441 - loss: 1.1476 - val_accuracy: 0.3192 - val_loss: 1.1537\n","Epoch 8/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.3075 - loss: 1.1511El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 362ms/step - accuracy: 0.3079 - loss: 1.1510 - val_accuracy: 0.3549 - val_loss: 1.1400\n","Epoch 9/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.3202 - loss: 1.1485El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 350ms/step - accuracy: 0.3203 - loss: 1.1484 - val_accuracy: 0.3192 - val_loss: 1.1446\n","Epoch 10/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.3402 - loss: 1.1395El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 337ms/step - accuracy: 0.3403 - loss: 1.1395 - val_accuracy: 0.3192 - val_loss: 1.1332\n","Epoch 11/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.3325 - loss: 1.1339El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 351ms/step - accuracy: 0.3323 - loss: 1.1340 - val_accuracy: 0.3259 - val_loss: 1.1330\n","Epoch 12/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.3216 - loss: 1.1396El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 366ms/step - accuracy: 0.3217 - loss: 1.1396 - val_accuracy: 0.3549 - val_loss: 1.1316\n","Epoch 13/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.2965 - loss: 1.1369El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 344ms/step - accuracy: 0.2968 - loss: 1.1369 - val_accuracy: 0.3549 - val_loss: 1.1303\n","Epoch 14/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.3371 - loss: 1.1323El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 342ms/step - accuracy: 0.3374 - loss: 1.1323 - val_accuracy: 0.3549 - val_loss: 1.1354\n","Epoch 15/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.3347 - loss: 1.1321El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 372ms/step - accuracy: 0.3347 - loss: 1.1321 - val_accuracy: 0.3259 - val_loss: 1.1295\n","Epoch 16/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.3320 - loss: 1.1334El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 336ms/step - accuracy: 0.3323 - loss: 1.1332 - val_accuracy: 0.3259 - val_loss: 1.1320\n","Epoch 17/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.3485 - loss: 1.1240El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 354ms/step - accuracy: 0.3482 - loss: 1.1240 - val_accuracy: 0.3259 - val_loss: 1.1253\n","Epoch 18/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.3776 - loss: 1.1218El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 372ms/step - accuracy: 0.3770 - loss: 1.1219 - val_accuracy: 0.3549 - val_loss: 1.1208\n","Epoch 19/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.3296 - loss: 1.1260El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 385ms/step - accuracy: 0.3298 - loss: 1.1260 - val_accuracy: 0.3549 - val_loss: 1.1425\n","Epoch 20/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.3583 - loss: 1.1251El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 332ms/step - accuracy: 0.3580 - loss: 1.1252 - val_accuracy: 0.3259 - val_loss: 1.1160\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","Epoch 1/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.3369 - loss: 7.4004El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 382ms/step - accuracy: 0.3366 - loss: 7.3737 - val_accuracy: 0.3259 - val_loss: 3.3778\n","Epoch 2/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.3325 - loss: 2.4694El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 353ms/step - accuracy: 0.3323 - loss: 2.4604 - val_accuracy: 0.3549 - val_loss: 1.4844\n","Epoch 3/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.3156 - loss: 1.4257El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 384ms/step - accuracy: 0.3157 - loss: 1.4261 - val_accuracy: 0.3549 - val_loss: 1.5213\n","Epoch 4/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.3356 - loss: 1.4747El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 350ms/step - accuracy: 0.3360 - loss: 1.4747 - val_accuracy: 0.4442 - val_loss: 1.3590\n","Epoch 5/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.3685 - loss: 1.3864El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 346ms/step - accuracy: 0.3685 - loss: 1.3859 - val_accuracy: 0.3259 - val_loss: 1.6350\n","Epoch 6/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.3868 - loss: 1.3903El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 383ms/step - accuracy: 0.3879 - loss: 1.3895 - val_accuracy: 0.5737 - val_loss: 1.2995\n","Epoch 7/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.5850 - loss: 1.2389El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 383ms/step - accuracy: 0.5858 - loss: 1.2382 - val_accuracy: 0.7946 - val_loss: 1.0479\n","Epoch 8/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.7669 - loss: 1.0365El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 384ms/step - accuracy: 0.7669 - loss: 1.0364 - val_accuracy: 0.7411 - val_loss: 1.0691\n","Epoch 9/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.8003 - loss: 0.9884El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 336ms/step - accuracy: 0.8003 - loss: 0.9885 - val_accuracy: 0.8192 - val_loss: 1.0217\n","Epoch 10/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.8488 - loss: 0.9380El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 353ms/step - accuracy: 0.8485 - loss: 0.9383 - val_accuracy: 0.7879 - val_loss: 0.9908\n","Epoch 11/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.8598 - loss: 0.8544El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 385ms/step - accuracy: 0.8595 - loss: 0.8549 - val_accuracy: 0.8237 - val_loss: 0.9748\n","Epoch 12/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.8777 - loss: 0.8429El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 347ms/step - accuracy: 0.8775 - loss: 0.8428 - val_accuracy: 0.8438 - val_loss: 1.0229\n","Epoch 13/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.8573 - loss: 0.9229El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 332ms/step - accuracy: 0.8574 - loss: 0.9221 - val_accuracy: 0.8839 - val_loss: 0.9149\n","Epoch 14/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.8742 - loss: 0.8199El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 352ms/step - accuracy: 0.8742 - loss: 0.8198 - val_accuracy: 0.7679 - val_loss: 1.0012\n","Epoch 15/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.8649 - loss: 0.8344El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 387ms/step - accuracy: 0.8653 - loss: 0.8337 - val_accuracy: 0.8862 - val_loss: 0.8462\n","Epoch 16/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.8855 - loss: 0.7794El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 349ms/step - accuracy: 0.8856 - loss: 0.7790 - val_accuracy: 0.8571 - val_loss: 0.8379\n","Epoch 17/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9081 - loss: 0.7188El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 365ms/step - accuracy: 0.9081 - loss: 0.7186 - val_accuracy: 0.9018 - val_loss: 0.7439\n","Epoch 18/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9120 - loss: 0.6800El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 341ms/step - accuracy: 0.9121 - loss: 0.6796 - val_accuracy: 0.8929 - val_loss: 0.7084\n","Epoch 19/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.9021 - loss: 0.6932El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 352ms/step - accuracy: 0.9021 - loss: 0.6933 - val_accuracy: 0.9286 - val_loss: 0.6645\n","Epoch 20/20\n","El número de lotes es de:  49\n","El número de lotes es de:  49\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.9350 - loss: 0.5960El número de lotes es de:  14\n","El número de lotes es de:  14\n","El número de lotes es de:  14\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 384ms/step - accuracy: 0.9346 - loss: 0.5967 - val_accuracy: 0.9085 - val_loss: 0.6803\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["El número de lotes es de:  7\n","El número de lotes es de:  7\n","El número de lotes es de:  7\n","El número de lotes es de:  7\n","El número de lotes es de:  7\n","El número de lotes es de:  7\n","El número de lotes es de:  7\n","El número de lotes es de:  7\n","El número de lotes es de:  7\n","El número de lotes es de:  7\n","El número de lotes es de:  7\n","El número de lotes es de:  7\n","El número de lotes es de:  7\n","El número de lotes es de:  7\n","El número de lotes es de:  7\n","El número de lotes es de:  7\n","El número de lotes es de:  7\n","El número de lotes es de:  7\n","El número de lotes es de:  7\n","El número de lotes es de:  7\n","Original -> Loss: 1.1012, Accuracy: 0.3213\n","L1 -> Loss: 0.6883, Accuracy: 0.8869\n","L2 -> Loss: 1.1161, Accuracy: 0.3258\n","L1+L2 -> Loss: 0.6591, Accuracy: 0.9140\n"]}]},{"cell_type":"markdown","source":["Elegir una regularización correcta, es crucial, en este casó la mejor opción es utilizar las dos opciones. Aún así, detacamos que la regularización *Lasso* es la que más aporta, por lo que podemos destacar que nuestro dataset se se beneficiaba más de la selección de características que de reducir magnitudes de pesos.\n","\n","A continuación, pasaremos expandir los datos de forma artificial con el fin de que generealice mejor. De esta forma, en cada batch se generen imágenes ligeramente modificadas, por lo que el modelo nunca ve dos veces exactamente el mismo dato. Previamente, deberemos convertir los arrays de nuestras imagenes, es decir, las direcciones, por arrays de imagenes, tipo float32."],"metadata":{"id":"w7viPgmmgAKS"}},{"cell_type":"code","source":["from tensorflow.keras import models, layers, optimizers, regularizers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.utils import load_img, img_to_array\n","import numpy as np\n","\n","def load_images(file_paths, target_size=(200,300)):\n","    images = []\n","    for path in file_paths:\n","        img = load_img(path, target_size=target_size)\n","        img_array = img_to_array(img) / 255.0\n","        images.append(img_array)\n","    return np.array(images, dtype=\"float32\")\n","\n","X_train_arr = load_images(X_train)\n","X_val_arr   = load_images(X_val)\n","\n","datagen = ImageDataGenerator(\n","    rotation_range=20,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","model = models.Sequential([\n","    layers.Conv2D(32, (3,3), activation='relu', input_shape=(200,300,3)),\n","    layers.MaxPooling2D((2,2)),\n","    layers.Flatten(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(3, activation='softmax')\n","])\n","\n","model.compile(\n","    optimizer=optimizers.Adam(),\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","\n","history = model.fit(\n","    datagen.flow(X_train_arr, y_train, batch_size=32),   # 👈 usar arrays\n","    validation_data=(X_val_arr, y_val),\n","    epochs=20\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kDv8p5LHKUKs","outputId":"baa1bc36-0a75-45db-939d-fb4b1927752f","executionInfo":{"status":"ok","timestamp":1756666756351,"user_tz":-120,"elapsed":278048,"user":{"displayName":"Juan Ramon","userId":"08272446682823668326"}}},"execution_count":8,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 2s/step - accuracy: 0.3698 - loss: 22.6568 - val_accuracy: 0.6719 - val_loss: 0.8701\n","Epoch 2/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.5694 - loss: 1.1442 - val_accuracy: 0.7902 - val_loss: 0.5884\n","Epoch 3/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.6768 - loss: 0.7470 - val_accuracy: 0.8638 - val_loss: 0.4763\n","Epoch 4/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 2s/step - accuracy: 0.8004 - loss: 0.5284 - val_accuracy: 0.8482 - val_loss: 0.4498\n","Epoch 5/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2s/step - accuracy: 0.7975 - loss: 0.5273 - val_accuracy: 0.7165 - val_loss: 0.5309\n","Epoch 6/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.7257 - loss: 0.6401 - val_accuracy: 0.8906 - val_loss: 0.3902\n","Epoch 7/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.7929 - loss: 0.5172 - val_accuracy: 0.9174 - val_loss: 0.3535\n","Epoch 8/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.8380 - loss: 0.4418 - val_accuracy: 0.9196 - val_loss: 0.3284\n","Epoch 9/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step - accuracy: 0.8651 - loss: 0.3797 - val_accuracy: 0.8795 - val_loss: 0.3741\n","Epoch 10/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2s/step - accuracy: 0.8272 - loss: 0.4351 - val_accuracy: 0.8973 - val_loss: 0.3630\n","Epoch 11/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 2s/step - accuracy: 0.8623 - loss: 0.3731 - val_accuracy: 0.9308 - val_loss: 0.2832\n","Epoch 12/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 2s/step - accuracy: 0.8803 - loss: 0.3802 - val_accuracy: 0.9219 - val_loss: 0.2628\n","Epoch 13/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 2s/step - accuracy: 0.8636 - loss: 0.4081 - val_accuracy: 0.9375 - val_loss: 0.2540\n","Epoch 14/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2s/step - accuracy: 0.8740 - loss: 0.3592 - val_accuracy: 0.9442 - val_loss: 0.2240\n","Epoch 15/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 0.8844 - loss: 0.3399 - val_accuracy: 0.9308 - val_loss: 0.2671\n","Epoch 16/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 0.9096 - loss: 0.2854 - val_accuracy: 0.9487 - val_loss: 0.1942\n","Epoch 17/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 2s/step - accuracy: 0.8994 - loss: 0.2988 - val_accuracy: 0.9576 - val_loss: 0.1929\n","Epoch 18/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 2s/step - accuracy: 0.8944 - loss: 0.2835 - val_accuracy: 0.9420 - val_loss: 0.2167\n","Epoch 19/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step - accuracy: 0.9305 - loss: 0.2611 - val_accuracy: 0.9018 - val_loss: 0.3089\n","Epoch 20/20\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 0.8691 - loss: 0.3544 - val_accuracy: 0.9509 - val_loss: 0.1788\n"]}]},{"cell_type":"markdown","source":["Por último, aplicaremos las técnica de transferencia del conocimiento que a traves de modelos ya preentrenados, es decir que no parten de 0, se entrena con ciertos modelos ya que saben reconocer bordes, texturas..."],"metadata":{"id":"ZRgUPF-Xgqi8"}},{"cell_type":"code","source":["from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras import models, layers, optimizers\n","\n","base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(200,300,3))\n","base_model.trainable = False\n","\n","transfer_model = models.Sequential([\n","    base_model,\n","    layers.GlobalAveragePooling2D(),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dropout(0.5),\n","    layers.Dense(3, activation='softmax')\n","])\n","\n","transfer_model.compile(\n","    optimizer=optimizers.Adam(learning_rate=1e-3),\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","history_tl = transfer_model.fit(\n","    datagen.flow(X_train_arr, y_train, batch_size=32),\n","    validation_data=(X_val_arr, y_val),\n","    epochs=10\n",")\n","\n","val_loss, val_acc = transfer_model.evaluate(X_val_arr, y_val, verbose=0)\n","print(f\"Transfer Learning -> Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q_yoSBKsI0ZV","executionInfo":{"status":"ok","timestamp":1756667566457,"user_tz":-120,"elapsed":799828,"user":{"displayName":"Juan Ramon","userId":"08272446682823668326"}},"outputId":"81b1d944-7fac-4d5a-8347-2f8e9a5d9ca7"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-22474338.py:4: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n","  base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(200,300,3))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step - accuracy: 0.7297 - loss: 0.6087 - val_accuracy: 0.9487 - val_loss: 0.1571\n","Epoch 2/10\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.9653 - loss: 0.1147 - val_accuracy: 0.9710 - val_loss: 0.0907\n","Epoch 3/10\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.9746 - loss: 0.0728 - val_accuracy: 0.9866 - val_loss: 0.0385\n","Epoch 4/10\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 2s/step - accuracy: 0.9830 - loss: 0.0563 - val_accuracy: 0.9777 - val_loss: 0.0599\n","Epoch 5/10\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 2s/step - accuracy: 0.9791 - loss: 0.0600 - val_accuracy: 0.9799 - val_loss: 0.0580\n","Epoch 6/10\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.9917 - loss: 0.0345 - val_accuracy: 0.9844 - val_loss: 0.0324\n","Epoch 7/10\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - accuracy: 0.9920 - loss: 0.0299 - val_accuracy: 0.9888 - val_loss: 0.0259\n","Epoch 8/10\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 2s/step - accuracy: 0.9934 - loss: 0.0243 - val_accuracy: 0.9754 - val_loss: 0.0648\n","Epoch 9/10\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 1s/step - accuracy: 0.9972 - loss: 0.0189 - val_accuracy: 0.9821 - val_loss: 0.0515\n","Epoch 10/10\n","\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 1s/step - accuracy: 0.9892 - loss: 0.0278 - val_accuracy: 0.9911 - val_loss: 0.0175\n","Transfer Learning -> Loss: 0.0175, Accuracy: 0.9911\n"]}]},{"cell_type":"markdown","source":["Nuestro modelo pareece ser bueno, puesto que ha llegado a una predicción de 99%. Previamente, con CNN llegaba a 93%. Sin embargo, ahora tras aplicarle transfer learning hemos conseguido mejorarlo.\n"],"metadata":{"id":"K_i2ys18zkwt"}},{"cell_type":"markdown","source":["Una vez desarrollados todos los modelos, los compararemos."],"metadata":{"id":"Q8cKKLr8xCaf"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","y_pred = np.argmax(transfer_model.predict(X_val_arr), axis=1)\n","\n","print(classification_report(y_val, y_pred, target_names=[\"Rock\",\"Paper\",\"Scissors\"]))\n","\n","cm = confusion_matrix(y_val, y_pred)\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Rock\",\"Paper\",\"Scissors\"], yticklabels=[\"Rock\",\"Paper\",\"Scissors\"])\n","plt.xlabel(\"Predicción\")\n","plt.ylabel(\"Real\")\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":636},"id":"ytmrHIsj4LF2","executionInfo":{"status":"ok","timestamp":1756667650553,"user_tz":-120,"elapsed":21617,"user":{"displayName":"Juan Ramon","userId":"08272446682823668326"}},"outputId":"edbdbefc-1df5-4168-949c-c68b9b1a9771"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 937ms/step\n","              precision    recall  f1-score   support\n","\n","        Rock       0.99      1.00      0.99       146\n","       Paper       0.99      0.99      0.99       143\n","    Scissors       1.00      0.99      0.99       159\n","\n","    accuracy                           0.99       448\n","   macro avg       0.99      0.99      0.99       448\n","weighted avg       0.99      0.99      0.99       448\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]}]}
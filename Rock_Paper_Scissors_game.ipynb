{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Rock-Paper-Scissors game"
      ],
      "metadata": {
        "id": "XcvYViAhhK6Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocesamiento y carga de datos"
      ],
      "metadata": {
        "id": "Hil5MdrcwtC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comenzaremos dandole los permisos necesarios para que Google Colab puede acceder a Google Drive. Seguidamente, generaremos las rutas pertenecientes a nuestros archivos que se encuentran en el propio Drive."
      ],
      "metadata": {
        "id": "H53euet1wRww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "k5dfyXh-vDVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39923163-8970-42dd-8731-1a8cfbfb4ca5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez montado y conectado nuestro notebook y dado los permisos necesarios para acceder a nuestra Unidad de Drive, generaremos las rutas sobre las que trabajaremos."
      ],
      "metadata": {
        "id": "wN_mpXHlvYQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/Tarea_final/Dataset\""
      ],
      "metadata": {
        "id": "oSgLoJVRvk97"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, debido al tamaño de nuestro dataset, debemos dividrlo por lotes, puesto que sino sería muy pesado en memoría. Para ello haremos uso de la función *Sequence* de Keras que nos ayudará a controlar la carga de los datos y mejorar el procesamiento de los mismos."
      ],
      "metadata": {
        "id": "iG6r1cvYw5As"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "class RPSSequence(Sequence):\n",
        "    def __init__(self, image_paths, labels, batch_size, target_size=(200, 300)):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.target_size = target_size\n",
        "\n",
        "    def __len__(self):\n",
        "        nLotes = int(np.ceil(len(self.image_paths) / self.batch_size))\n",
        "        print(\"El número de lotes es de: \", nLotes)\n",
        "        return nLotes\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_paths = self.image_paths[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "        batch_labels = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
        "\n",
        "        batch_images = []\n",
        "        for path in batch_paths:\n",
        "            img = cv2.imread(path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img = cv2.resize(img, self.target_size)\n",
        "            img = img / 255.0\n",
        "            batch_images.append(img)\n",
        "\n",
        "        return np.array(batch_images), np.array(batch_labels)\n"
      ],
      "metadata": {
        "id": "teCIL5pAygyx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar, hemos creado una clase, típica, para manejar la inyección de datos. En un primer lugar hemos definido las propiedades de la clase en el método init. Seguidamente, en el método len estudiamos el número de lotes en los que los dividiremos. Por último, la función getitem da al conjunto de entreamiento un lote cada vez que lo requiera el modelo.\n",
        "\n",
        "A continuación viene el apartado del preprocesamiento. Sin embargo, en nuestra funcióna anterior ya hemos avanzado en este tema con dos pasos.  El primero de ellos ha sido el escalar las imagenes al realizar:\n",
        "```\n",
        "img = img / 255.0  \n",
        "```"
      ],
      "metadata": {
        "id": "Or5rWZWKyrZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con esto pretendemos es acotar el rango ya que como va de [0,255] relentizaría bastante el preprocesamiento, por lo que ahora se movería en un rango de [0,1].\n",
        "\n",
        "Otra acción ha sido la redimensión de las imagenes ya que todos los modelos de DL necesitan de que todas las imagenes reciban el mismo tamaño. Para ello hemos hecho uso de la función:\n",
        "```\n",
        "img = cv2.resize(img, self.target_size)\n",
        "```"
      ],
      "metadata": {
        "id": "yEnXZzVy25hU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gracias a estas dos acciones conseguimos uniformidad en el tamaño de las imagenes y normalización.\n",
        "\n",
        "Ahora, podemos dividir el conjunto de datos que lo separaremos en: train (70%), val (20%) y test (10%)."
      ],
      "metadata": {
        "id": "1K21m1zh3lHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "clases = {\"rock\": 0, \"paper\": 1, \"scissors\": 2}\n",
        "\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "for clase, idx in clases.items():\n",
        "    paths = glob.glob(os.path.join(dataset_path, clase, \"*.png\"))\n",
        "    image_paths.extend(paths)\n",
        "    labels.extend([idx] * len(paths))\n",
        "\n",
        "image_paths = np.array(image_paths)\n",
        "labels = np.array(labels)\n",
        "\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(image_paths, labels, test_size=0.3, stratify=labels, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.33, stratify=y_temp, random_state=42)\n",
        "\n",
        "print(f\"Para el conjunto train (70%) contamos con: {len(X_train)} imagenes.\")\n",
        "print(f\"Para el conjunto val (20%) contamos con: {len(X_val)} imagenes.\")\n",
        "print(f\"Para el conjunto test (10%) contamos con: {len(X_test)} imagenes.\")"
      ],
      "metadata": {
        "id": "tKKbj0Bl0ZQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33cc297f-66e8-47d2-f9f5-00a88a1a35c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Para el conjunto train (70%) contamos con: 1558 imagenes.\n",
            "Para el conjunto val (20%) contamos con: 448 imagenes.\n",
            "Para el conjunto test (10%) contamos con: 221 imagenes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez dividos los conjuntos haremos uso de la función previamente creada, *class RPSSequence*, para dividir los datos en los lotes anteriomente explicado. En este caso utilizaremos un batch_size de 32 ya que nos aporta menos memoria RAM, nos ayuda a generalizar y es más ruidoso."
      ],
      "metadata": {
        "id": "fHnSlYua-QCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_gen = RPSSequence(X_train, y_train, batch_size=batch_size)\n",
        "val_gen = RPSSequence(X_val, y_val, batch_size=batch_size)\n",
        "test_gen = RPSSequence(X_test, y_test, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "rUtBqaS6-9R6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrenamiento de modelos"
      ],
      "metadata": {
        "id": "MbDlQEXoxCjD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta nueva sección generaremos distintos modelos de DL, con el fin de aproximarnos a aquel que nos arroje los mejores resultados.\n",
        "\n",
        "Crearemos una red nueronal convolucional (CNN), que son las especializadas en el preprocesamiento de imagenes, a partir de la detección de bordes, texturas..."
      ],
      "metadata": {
        "id": "B-ef2tC78FWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(200,300,3)),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "697HI7pE95BX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3751ca0f-ec50-4b61-f2ad-6cca68ee0cc3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comenzaremos a desgranar este modelo. En primer lugar le atribuimos kernel de 32 don el fin de detectar patrones. A mayor valor, más aprendizaje pero mayor riesgo de overfitting. Por otro lado, tenemos un tamaño de filto de 3 de alto y ancho, esto es el area de la imagen que observará. Seguidamente hemos propuesto como función de activación la relu y una dimensión de entrada de 200x300px y 3 canales rgb.\n",
        "\n",
        "A continuación en MaxPooling2D reducimos las caracteristicas de la imagen a la mitad, por el (2,2) para su capturación.\n",
        "\n",
        "Por último, declaramos que la red debe tener 128 neuronas y tendrá una salida de 3 grupos, por scissors, paper y rock.\n",
        "\n",
        "Una vez generada esta primera red neuronal, marcamos la función perdida, el optimizador y la métrica."
      ],
      "metadata": {
        "id": "ttD8KFKZG9UT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ydi-h6Q5Js_m"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=5,\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMx1v5lEKYhm",
        "outputId": "fb6bdaf8-c540-44a4-a31c-6f889e11a9b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "Epoch 1/5\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.4165 - loss: 17.6041El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 8s/step - accuracy: 0.4185 - loss: 17.4084 - val_accuracy: 0.7924 - val_loss: 0.5884\n",
            "Epoch 2/5\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.8391 - loss: 0.4502El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 356ms/step - accuracy: 0.8395 - loss: 0.4495 - val_accuracy: 0.8772 - val_loss: 0.4222\n",
            "Epoch 3/5\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.8974 - loss: 0.3038El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 386ms/step - accuracy: 0.8978 - loss: 0.3033 - val_accuracy: 0.8750 - val_loss: 0.4024\n",
            "Epoch 4/5\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.9281 - loss: 0.2141El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 358ms/step - accuracy: 0.9281 - loss: 0.2142 - val_accuracy: 0.9018 - val_loss: 0.3429\n",
            "Epoch 5/5\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.9480 - loss: 0.1698El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 357ms/step - accuracy: 0.9480 - loss: 0.1699 - val_accuracy: 0.8906 - val_loss: 0.3351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para observar los resultados más correctamente los visualizaremos en la siguiente tabla, y a continuación discutiremos los resultados.\n",
        "\n",
        "| Época | Accuracy (train) | Loss (train) | Accuracy (val) | Loss (val) |\n",
        "| ----- | ---------------- | ------------ | -------------- | ---------- |\n",
        "| 1     | 41.65 %          | 17.6041      | 79.24 %        | 0.5884     |\n",
        "| 2     | 83.95 %          | 0.4495       | 87.72 %        | 0.4222     |\n",
        "| 3     | 89.78 %          | 0.3033       | 87.50 %        | 0.4024     |\n",
        "| 4     | 92.81 %          | 0.2142       | 90.18 %        | 0.3429     |\n",
        "| 5     | 94.80 %          | 0.1699       | 89.06 %        | 0.3351     |\n",
        "\n",
        "En la primera época observamos un mal accuracy y una función perdida alta. Esto es esperable al estar iniciandose.\n",
        "\n",
        "De la segunda a la última época observamos como el accuracy mejora progresivamete, al igual que la función de perdida se aminora. Sin embargo, el accierto en val en la última época disminuye y la función perdida supera a la de la epoca 3. Es por ello que podemos entender que el modelo tiende a sobreajuste, por lo que el modelo empieza a memorizar demasiado el train."
      ],
      "metadata": {
        "id": "o9mq3RNR8Djf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación realizaremos un ajuste de hiperparametros. Para ello utilizaremos la herramienta **Keras Tuner** la cual sirve para probar combinaciones automáticamente."
      ],
      "metadata": {
        "id": "zFQouoHtPTTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner --quiet"
      ],
      "metadata": {
        "id": "p9U1PHtiiJ5r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "811c1fb9-464e-4957-bc69-f620e6bccb07"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(\n",
        "        filters=hp.Choice(\"conv_filters\", values=[32, 64, 128]),\n",
        "        kernel_size=hp.Choice(\"kernel_size\", values=[3,5]),\n",
        "        activation=hp.Choice(\"conv_activation\", [\"relu\", \"tanh\", \"sigmoid\"]),\n",
        "        input_shape=(200,300,3)\n",
        "    ))\n",
        "    model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "    if hp.Boolean(\"use_dropout\"):\n",
        "        model.add(Dropout(rate=0.3))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(\n",
        "        units=hp.Choice(\"dense_units\", values=[64, 128, 256]),\n",
        "        activation='relu'\n",
        "    ))\n",
        "\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=hp.Choice(\"optimizer\", values=[\"adam\", \"sgd\", \"rmsprop\"]),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=5,\n",
        "    directory=\"tuner_results\",\n",
        "    project_name=\"rps\"\n",
        ")\n",
        "\n",
        "tuner.search(train_gen, validation_data=val_gen, epochs=5)\n",
        "\n",
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "A_hrpay2PoDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f87dd46-6851-41a3-a4b8-f8d9212e11f6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 02m 23s]\n",
            "val_accuracy: 0.640625\n",
            "\n",
            "Best val_accuracy So Far: 0.9084821343421936\n",
            "Total elapsed time: 00h 11m 55s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos observar, el accurcy que capta es del 87%, por lo que es bastante bueno. Ahora veremos cuales son de la función perdida de train, así como en val."
      ],
      "metadata": {
        "id": "R6m-nHydZuN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "history = best_model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=5\n",
        ")\n",
        "\n",
        "train_loss, train_acc = best_model.evaluate(train_gen, verbose=0)\n",
        "val_loss, val_acc = best_model.evaluate(val_gen, verbose=0)"
      ],
      "metadata": {
        "id": "WNWFR0b7Z_F6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad3d68ee-a979-4345-e9e9-3613d952b98c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "Epoch 1/5\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.9426 - loss: 0.2012El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 501ms/step - accuracy: 0.9425 - loss: 0.2011 - val_accuracy: 0.9129 - val_loss: 0.2644\n",
            "Epoch 2/5\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.9604 - loss: 0.1458El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 437ms/step - accuracy: 0.9603 - loss: 0.1459 - val_accuracy: 0.8951 - val_loss: 0.2976\n",
            "Epoch 3/5\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.9532 - loss: 0.1401El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 345ms/step - accuracy: 0.9534 - loss: 0.1399 - val_accuracy: 0.9420 - val_loss: 0.2076\n",
            "Epoch 4/5\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.9723 - loss: 0.0967El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 369ms/step - accuracy: 0.9722 - loss: 0.0969 - val_accuracy: 0.9174 - val_loss: 0.2808\n",
            "Epoch 5/5\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.9688 - loss: 0.1010El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 350ms/step - accuracy: 0.9688 - loss: 0.1008 - val_accuracy: 0.9375 - val_loss: 0.2078\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El resultado, ya con los hiperparametros ajustados es:\n",
        "\n",
        "| Época | Accuracy (train) | Loss (train) | Accuracy (val) | Loss (val) |\n",
        "| ----- | ---------------- | ------------ | -------------- | ---------- |\n",
        "| 1     | 94.25 %          | 0.2011       | 91.29 %        | 0.2644     |\n",
        "| 2     | 96.03 %          | 0.1459       | 89.51 %        | 0.2976     |\n",
        "| 3     | 95.34 %          | 0.1399       | 94.20 %        | 0.2076     |\n",
        "| 4     | 97.22 %          | 0.0969       | 91.74 %        | 0.2808     |\n",
        "| 5     | 96.88 %          | 0.1008       | 93.75 %        | 0.2078     |\n",
        "\n",
        "\n",
        "Aqui podemos observar que hasta el tercer epoch sube linealmente, para en el cuarto descender levemente y en el quinto y último epochs tener el máximo de trains accuracy. A su vez la función perdidia en train es al más baja. De la misma forma, respecto a val, obtenemos uno de los mejores resultados y aunque no sea la mejor funcion perdida, es igualmente uno de los mejores resultados.\n",
        "\n",
        "A continuación observaremos cuales son los mejores hiperparametros que nos marca Keras Turner."
      ],
      "metadata": {
        "id": "QIgkMFU8tN5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "for param, value in best_hps.values.items():\n",
        "    print(f\"{param}: {value}\")"
      ],
      "metadata": {
        "id": "g-sAMHCzYbJQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9954f273-0168-4506-c489-25bdc8212023"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv_filters: 64\n",
            "kernel_size: 3\n",
            "conv_activation: tanh\n",
            "use_dropout: True\n",
            "dense_units: 64\n",
            "optimizer: sgd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los parámetros que hemos ajustado que componen esta última red neuronal son. En la parte convolucional, cambiamos a 64 filtros y una kernel de 3x3. Sin embargo, la función de activación es la tangente. En la regularización este modelo ha optado por usar el dropout. Por último, mencionaremos el optimizador que ha pasado de ser adams a sgd, puesto que tiende a ir mejor en problemas de imágenes y secuencias.\n",
        "\n",
        "A continuación, realizaremos técnicas de regularización Lasso, que penaliza los coeficientes absolutos, y Ridge, que se encarga de el cuadrado de los coeficientes. Los evaluaremos independientes con el fin de obtener el mejor resultado."
      ],
      "metadata": {
        "id": "bP_p91TT8C7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models, layers, optimizers, regularizers\n",
        "\n",
        "def build_model(reg_type=None, l1_val=1e-5, l2_val=1e-4):\n",
        "    if reg_type == \"l1\":\n",
        "        reg = regularizers.l1(l1_val)\n",
        "    elif reg_type == \"l2\":\n",
        "        reg = regularizers.l2(l2_val)\n",
        "    elif reg_type == \"l1_l2\":\n",
        "        reg = regularizers.l1_l2(l1=l1_val, l2=l2_val)\n",
        "    else:\n",
        "        reg = None\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3,3), activation='tanh', input_shape=(200,300,3),\n",
        "                      kernel_regularizer=reg),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='tanh', kernel_regularizer=reg),\n",
        "        layers.Dense(3, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "    optimizer=optimizers.RMSprop(),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "model_original = build_model(reg_type=None)\n",
        "model_l1       = build_model(reg_type=\"l1\")\n",
        "model_l2       = build_model(reg_type=\"l2\")\n",
        "model_l1_l2    = build_model(reg_type=\"l1_l2\")\n",
        "\n",
        "history_original = model_original.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=20\n",
        ")\n",
        "\n",
        "history_l1 = model_l1.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=20\n",
        ")\n",
        "\n",
        "history_l2 = model_l2.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=20\n",
        ")\n",
        "\n",
        "history_l1_l2 = model_l1_l2.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=20\n",
        ")\n",
        "\n",
        "results = {\n",
        "    \"Original\": model_original.evaluate(test_gen, verbose=0),\n",
        "    \"L1\": model_l1.evaluate(test_gen, verbose=0),\n",
        "    \"L2\": model_l2.evaluate(test_gen, verbose=0),\n",
        "    \"L1+L2\": model_l1_l2.evaluate(test_gen, verbose=0)\n",
        "}\n",
        "\n",
        "for name, (loss, acc) in results.items():\n",
        "    print(f\"{name} -> Loss: {loss:.4f}, Accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "id": "rROiq4KrOlnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f22263-25c9-4dc8-e0b2-4fcf66cb356d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "Epoch 1/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.3230 - loss: 4.1083El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 362ms/step - accuracy: 0.3231 - loss: 4.0966 - val_accuracy: 0.3549 - val_loss: 1.6856\n",
            "Epoch 2/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.3525 - loss: 1.3195El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 354ms/step - accuracy: 0.3524 - loss: 1.3168 - val_accuracy: 0.3259 - val_loss: 1.0992\n",
            "Epoch 3/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.3402 - loss: 1.1089El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 372ms/step - accuracy: 0.3401 - loss: 1.1089 - val_accuracy: 0.3259 - val_loss: 1.1005\n",
            "Epoch 4/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.3463 - loss: 1.1082El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 346ms/step - accuracy: 0.3462 - loss: 1.1082 - val_accuracy: 0.3549 - val_loss: 1.1187\n",
            "Epoch 5/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.3385 - loss: 1.1083El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 342ms/step - accuracy: 0.3384 - loss: 1.1083 - val_accuracy: 0.3549 - val_loss: 1.0998\n",
            "Epoch 6/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.3501 - loss: 1.1097El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 386ms/step - accuracy: 0.3502 - loss: 1.1096 - val_accuracy: 0.3549 - val_loss: 1.1036\n",
            "Epoch 7/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.3181 - loss: 1.1116El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 353ms/step - accuracy: 0.3182 - loss: 1.1115 - val_accuracy: 0.3192 - val_loss: 1.1475\n",
            "Epoch 8/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.3424 - loss: 1.1104El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 347ms/step - accuracy: 0.3424 - loss: 1.1103 - val_accuracy: 0.3549 - val_loss: 1.1110\n",
            "Epoch 9/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.3314 - loss: 1.1034El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 343ms/step - accuracy: 0.3316 - loss: 1.1034 - val_accuracy: 0.3192 - val_loss: 1.1072\n",
            "Epoch 10/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.3124 - loss: 1.1146El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 351ms/step - accuracy: 0.3126 - loss: 1.1145 - val_accuracy: 0.3259 - val_loss: 1.1028\n",
            "Epoch 11/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.3256 - loss: 1.1087El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 377ms/step - accuracy: 0.3256 - loss: 1.1088 - val_accuracy: 0.3549 - val_loss: 1.0991\n",
            "Epoch 12/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.3499 - loss: 1.1076El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 347ms/step - accuracy: 0.3497 - loss: 1.1076 - val_accuracy: 0.3192 - val_loss: 1.1033\n",
            "Epoch 13/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.3403 - loss: 1.1043El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 373ms/step - accuracy: 0.3402 - loss: 1.1044 - val_accuracy: 0.3549 - val_loss: 1.0981\n",
            "Epoch 14/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.3678 - loss: 1.1037El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 357ms/step - accuracy: 0.3676 - loss: 1.1037 - val_accuracy: 0.3549 - val_loss: 1.0982\n",
            "Epoch 15/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.3468 - loss: 1.1101El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 370ms/step - accuracy: 0.3468 - loss: 1.1101 - val_accuracy: 0.3549 - val_loss: 1.0997\n",
            "Epoch 16/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.3164 - loss: 1.1095El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 347ms/step - accuracy: 0.3168 - loss: 1.1095 - val_accuracy: 0.3549 - val_loss: 1.1137\n",
            "Epoch 17/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.3434 - loss: 1.1108El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 341ms/step - accuracy: 0.3436 - loss: 1.1107 - val_accuracy: 0.3259 - val_loss: 1.1024\n",
            "Epoch 18/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.3235 - loss: 1.1093El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 351ms/step - accuracy: 0.3235 - loss: 1.1094 - val_accuracy: 0.3259 - val_loss: 1.1062\n",
            "Epoch 19/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.3402 - loss: 1.1087El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 377ms/step - accuracy: 0.3401 - loss: 1.1087 - val_accuracy: 0.3259 - val_loss: 1.1012\n",
            "Epoch 20/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.3155 - loss: 1.1115El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 352ms/step - accuracy: 0.3159 - loss: 1.1114 - val_accuracy: 0.3549 - val_loss: 1.1036\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "Epoch 1/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.3222 - loss: 5.1950El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 408ms/step - accuracy: 0.3225 - loss: 5.1765 - val_accuracy: 0.3549 - val_loss: 2.2274\n",
            "Epoch 2/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.3263 - loss: 1.9405El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 350ms/step - accuracy: 0.3263 - loss: 1.9378 - val_accuracy: 0.3259 - val_loss: 1.5457\n",
            "Epoch 3/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.3404 - loss: 1.4746El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 350ms/step - accuracy: 0.3404 - loss: 1.4734 - val_accuracy: 0.3549 - val_loss: 1.3850\n",
            "Epoch 4/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.3656 - loss: 1.2989El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 361ms/step - accuracy: 0.3653 - loss: 1.2997 - val_accuracy: 0.3259 - val_loss: 1.4601\n",
            "Epoch 5/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.3234 - loss: 1.4771El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 336ms/step - accuracy: 0.3240 - loss: 1.4770 - val_accuracy: 0.4799 - val_loss: 1.4604\n",
            "Epoch 6/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.4337 - loss: 1.3960El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 338ms/step - accuracy: 0.4344 - loss: 1.3952 - val_accuracy: 0.7076 - val_loss: 1.2767\n",
            "Epoch 7/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.6194 - loss: 1.3135El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 355ms/step - accuracy: 0.6201 - loss: 1.3127 - val_accuracy: 0.6853 - val_loss: 1.2209\n",
            "Epoch 8/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.7298 - loss: 1.1623El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 362ms/step - accuracy: 0.7302 - loss: 1.1619 - val_accuracy: 0.7969 - val_loss: 1.0565\n",
            "Epoch 9/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.7566 - loss: 1.1292El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 336ms/step - accuracy: 0.7572 - loss: 1.1281 - val_accuracy: 0.8103 - val_loss: 1.0180\n",
            "Epoch 10/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.8104 - loss: 1.0218El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 337ms/step - accuracy: 0.8106 - loss: 1.0219 - val_accuracy: 0.8237 - val_loss: 1.0409\n",
            "Epoch 11/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.8621 - loss: 0.9149El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 387ms/step - accuracy: 0.8617 - loss: 0.9154 - val_accuracy: 0.8192 - val_loss: 1.0496\n",
            "Epoch 12/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.8250 - loss: 0.9801El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 346ms/step - accuracy: 0.8252 - loss: 0.9796 - val_accuracy: 0.8371 - val_loss: 0.9899\n",
            "Epoch 13/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.8826 - loss: 0.8790El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 339ms/step - accuracy: 0.8825 - loss: 0.8788 - val_accuracy: 0.8393 - val_loss: 0.9668\n",
            "Epoch 14/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.8753 - loss: 0.8585El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 365ms/step - accuracy: 0.8751 - loss: 0.8590 - val_accuracy: 0.8504 - val_loss: 0.9347\n",
            "Epoch 15/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.8800 - loss: 0.8513El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 352ms/step - accuracy: 0.8801 - loss: 0.8511 - val_accuracy: 0.8817 - val_loss: 0.8485\n",
            "Epoch 16/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.8893 - loss: 0.7956El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 338ms/step - accuracy: 0.8890 - loss: 0.7962 - val_accuracy: 0.8795 - val_loss: 0.8711\n",
            "Epoch 17/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9053 - loss: 0.7646El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 369ms/step - accuracy: 0.9050 - loss: 0.7651 - val_accuracy: 0.8772 - val_loss: 0.8682\n",
            "Epoch 18/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.9182 - loss: 0.7609El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 386ms/step - accuracy: 0.9176 - loss: 0.7618 - val_accuracy: 0.8929 - val_loss: 0.8493\n",
            "Epoch 19/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.8958 - loss: 0.7715El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 356ms/step - accuracy: 0.8958 - loss: 0.7712 - val_accuracy: 0.8839 - val_loss: 0.8216\n",
            "Epoch 20/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.9133 - loss: 0.7511El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 357ms/step - accuracy: 0.9133 - loss: 0.7511 - val_accuracy: 0.8795 - val_loss: 0.8228\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "Epoch 1/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.3208 - loss: 6.5698El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 396ms/step - accuracy: 0.3208 - loss: 6.5409 - val_accuracy: 0.3259 - val_loss: 2.4235\n",
            "Epoch 2/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.3421 - loss: 1.7309El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 347ms/step - accuracy: 0.3420 - loss: 1.7251 - val_accuracy: 0.3259 - val_loss: 1.1522\n",
            "Epoch 3/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.3602 - loss: 1.1546El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 347ms/step - accuracy: 0.3600 - loss: 1.1546 - val_accuracy: 0.3259 - val_loss: 1.1866\n",
            "Epoch 4/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.3139 - loss: 1.1632El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 373ms/step - accuracy: 0.3138 - loss: 1.1632 - val_accuracy: 0.3259 - val_loss: 1.1455\n",
            "Epoch 5/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.3341 - loss: 1.1544El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 349ms/step - accuracy: 0.3344 - loss: 1.1543 - val_accuracy: 0.3549 - val_loss: 1.1454\n",
            "Epoch 6/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.3777 - loss: 1.1410El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 351ms/step - accuracy: 0.3773 - loss: 1.1410 - val_accuracy: 0.3549 - val_loss: 1.1553\n",
            "Epoch 7/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.3419 - loss: 1.1447El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 372ms/step - accuracy: 0.3419 - loss: 1.1447 - val_accuracy: 0.3549 - val_loss: 1.1378\n",
            "Epoch 8/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.3262 - loss: 1.1461El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 342ms/step - accuracy: 0.3261 - loss: 1.1461 - val_accuracy: 0.3549 - val_loss: 1.1341\n",
            "Epoch 9/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.3425 - loss: 1.1435El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 356ms/step - accuracy: 0.3425 - loss: 1.1435 - val_accuracy: 0.3259 - val_loss: 1.1469\n",
            "Epoch 10/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.3091 - loss: 1.1449El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 360ms/step - accuracy: 0.3094 - loss: 1.1448 - val_accuracy: 0.3259 - val_loss: 1.1334\n",
            "Epoch 11/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.3165 - loss: 1.1427El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 340ms/step - accuracy: 0.3169 - loss: 1.1426 - val_accuracy: 0.3549 - val_loss: 1.1442\n",
            "Epoch 12/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step - accuracy: 0.3226 - loss: 1.1371El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 349ms/step - accuracy: 0.3229 - loss: 1.1371 - val_accuracy: 0.3259 - val_loss: 1.1272\n",
            "Epoch 13/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.3497 - loss: 1.1391El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 382ms/step - accuracy: 0.3497 - loss: 1.1391 - val_accuracy: 0.3259 - val_loss: 1.1286\n",
            "Epoch 14/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.3402 - loss: 1.1312El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 341ms/step - accuracy: 0.3400 - loss: 1.1312 - val_accuracy: 0.3259 - val_loss: 1.1373\n",
            "Epoch 15/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.3675 - loss: 1.1299El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 337ms/step - accuracy: 0.3674 - loss: 1.1299 - val_accuracy: 0.3549 - val_loss: 1.1254\n",
            "Epoch 16/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.3537 - loss: 1.1247El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 343ms/step - accuracy: 0.3533 - loss: 1.1248 - val_accuracy: 0.3259 - val_loss: 1.1239\n",
            "Epoch 17/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.3505 - loss: 1.1276El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 354ms/step - accuracy: 0.3502 - loss: 1.1276 - val_accuracy: 0.3549 - val_loss: 1.1190\n",
            "Epoch 18/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 0.3204 - loss: 1.1300El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 344ms/step - accuracy: 0.3208 - loss: 1.1299 - val_accuracy: 0.3549 - val_loss: 1.1287\n",
            "Epoch 19/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.3416 - loss: 1.1282El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 354ms/step - accuracy: 0.3414 - loss: 1.1282 - val_accuracy: 0.3549 - val_loss: 1.1159\n",
            "Epoch 20/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.3329 - loss: 1.1236El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 343ms/step - accuracy: 0.3328 - loss: 1.1236 - val_accuracy: 0.3259 - val_loss: 1.1322\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "Epoch 1/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 0.3073 - loss: 6.1073El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 403ms/step - accuracy: 0.3074 - loss: 6.0906 - val_accuracy: 0.3192 - val_loss: 2.9060\n",
            "Epoch 2/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.2806 - loss: 2.3517El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 350ms/step - accuracy: 0.2815 - loss: 2.3438 - val_accuracy: 0.3192 - val_loss: 1.5631\n",
            "Epoch 3/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.3335 - loss: 1.4887El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 337ms/step - accuracy: 0.3332 - loss: 1.4878 - val_accuracy: 0.3549 - val_loss: 1.3222\n",
            "Epoch 4/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.3716 - loss: 1.3506El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 365ms/step - accuracy: 0.3716 - loss: 1.3512 - val_accuracy: 0.4062 - val_loss: 1.4403\n",
            "Epoch 5/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.4725 - loss: 1.4884El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 343ms/step - accuracy: 0.4736 - loss: 1.4870 - val_accuracy: 0.6629 - val_loss: 1.2710\n",
            "Epoch 6/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.6375 - loss: 1.2777El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 346ms/step - accuracy: 0.6382 - loss: 1.2768 - val_accuracy: 0.7969 - val_loss: 1.0699\n",
            "Epoch 7/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.7850 - loss: 1.0439El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 336ms/step - accuracy: 0.7848 - loss: 1.0442 - val_accuracy: 0.8438 - val_loss: 0.9620\n",
            "Epoch 8/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.8397 - loss: 0.8996El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 334ms/step - accuracy: 0.8394 - loss: 0.9003 - val_accuracy: 0.7857 - val_loss: 1.0458\n",
            "Epoch 9/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.8485 - loss: 0.8910El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 348ms/step - accuracy: 0.8485 - loss: 0.8906 - val_accuracy: 0.8728 - val_loss: 0.8458\n",
            "Epoch 10/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.8742 - loss: 0.8072El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 355ms/step - accuracy: 0.8739 - loss: 0.8079 - val_accuracy: 0.8906 - val_loss: 0.8337\n",
            "Epoch 11/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.8894 - loss: 0.7663El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 399ms/step - accuracy: 0.8893 - loss: 0.7665 - val_accuracy: 0.8973 - val_loss: 0.7904\n",
            "Epoch 12/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.8989 - loss: 0.7110El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 359ms/step - accuracy: 0.8986 - loss: 0.7117 - val_accuracy: 0.8929 - val_loss: 0.7483\n",
            "Epoch 13/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.8844 - loss: 0.7605El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 369ms/step - accuracy: 0.8847 - loss: 0.7596 - val_accuracy: 0.8728 - val_loss: 0.7809\n",
            "Epoch 14/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.9298 - loss: 0.6342El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 348ms/step - accuracy: 0.9294 - loss: 0.6349 - val_accuracy: 0.8996 - val_loss: 0.7335\n",
            "Epoch 15/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9210 - loss: 0.6459El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 366ms/step - accuracy: 0.9207 - loss: 0.6465 - val_accuracy: 0.8795 - val_loss: 0.8074\n",
            "Epoch 16/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.9290 - loss: 0.6048El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 347ms/step - accuracy: 0.9290 - loss: 0.6047 - val_accuracy: 0.9152 - val_loss: 0.6662\n",
            "Epoch 17/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.9206 - loss: 0.5922El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 348ms/step - accuracy: 0.9207 - loss: 0.5919 - val_accuracy: 0.8973 - val_loss: 0.6119\n",
            "Epoch 18/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.9250 - loss: 0.5569El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 351ms/step - accuracy: 0.9251 - loss: 0.5567 - val_accuracy: 0.8527 - val_loss: 0.7354\n",
            "Epoch 19/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9268 - loss: 0.5781El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 332ms/step - accuracy: 0.9270 - loss: 0.5772 - val_accuracy: 0.9263 - val_loss: 0.5796\n",
            "Epoch 20/20\n",
            "El número de lotes es de:  49\n",
            "El número de lotes es de:  49\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9386 - loss: 0.5092El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "El número de lotes es de:  14\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 343ms/step - accuracy: 0.9386 - loss: 0.5093 - val_accuracy: 0.9152 - val_loss: 0.6048\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "El número de lotes es de:  7\n",
            "Original -> Loss: 1.1043, Accuracy: 0.3529\n",
            "L1 -> Loss: 0.7506, Accuracy: 0.9095\n",
            "L2 -> Loss: 1.1329, Accuracy: 0.3258\n",
            "L1+L2 -> Loss: 0.5401, Accuracy: 0.9321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elegir una regularización correcta, es crucial, en este casó la mejor opción es utilizar las dos opciones. Aún así, detacamos que la regularización *Lasso* es la que más aporta, por lo que podemos destacar que nuestro dataset se se beneficiaba más de la selección de características que de reducir magnitudes de pesos.\n",
        "\n",
        "A continuación, pasaremos expandir los datos de forma artificial con el fin de que generealice mejor. De esta forma, en cada batch se generen imágenes ligeramente modificadas, por lo que el modelo nunca ve dos veces exactamente el mismo dato. Previamente, deberemos convertir los arrays de nuestras imagenes, es decir, las direcciones, por arrays de imagenes, tipo float32."
      ],
      "metadata": {
        "id": "w7viPgmmgAKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models, layers, optimizers, regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import numpy as np\n",
        "\n",
        "def load_images(file_paths, target_size=(128,192)):\n",
        "    images = []\n",
        "    for path in file_paths:\n",
        "        img = load_img(path, target_size=target_size)\n",
        "        img_array = img_to_array(img) / 255.0\n",
        "        images.append(img_array)\n",
        "    return np.array(images, dtype=\"float32\")\n",
        "\n",
        "X_train_arr = load_images(X_train)\n",
        "X_val_arr   = load_images(X_val)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(16, (3,3), activation='relu', input_shape=(128,192,3)),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizers.Adam(),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    datagen.flow(X_train_arr, y_train, batch_size=8),\n",
        "    validation_data=(X_val_arr, y_val),\n",
        "    epochs=20\n",
        ")"
      ],
      "metadata": {
        "id": "kDv8p5LHKUKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f0b465e-d6a6-4322-cc53-2b44ce3c67a2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 63ms/step - accuracy: 0.4518 - loss: 2.1686 - val_accuracy: 0.4286 - val_loss: 0.9373\n",
            "Epoch 2/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.6890 - loss: 0.7594 - val_accuracy: 0.6853 - val_loss: 0.6675\n",
            "Epoch 3/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.7637 - loss: 0.6083 - val_accuracy: 0.9040 - val_loss: 0.3431\n",
            "Epoch 4/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.8261 - loss: 0.4840 - val_accuracy: 0.7835 - val_loss: 0.5119\n",
            "Epoch 5/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.8064 - loss: 0.5319 - val_accuracy: 0.9241 - val_loss: 0.2561\n",
            "Epoch 6/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.8705 - loss: 0.3421 - val_accuracy: 0.9286 - val_loss: 0.2222\n",
            "Epoch 7/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.8789 - loss: 0.3039 - val_accuracy: 0.9487 - val_loss: 0.1844\n",
            "Epoch 8/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.9040 - loss: 0.2772 - val_accuracy: 0.9509 - val_loss: 0.1654\n",
            "Epoch 9/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.9001 - loss: 0.2608 - val_accuracy: 0.9621 - val_loss: 0.1515\n",
            "Epoch 10/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.9129 - loss: 0.2373 - val_accuracy: 0.9397 - val_loss: 0.1819\n",
            "Epoch 11/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.9081 - loss: 0.2648 - val_accuracy: 0.9576 - val_loss: 0.1294\n",
            "Epoch 12/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.9221 - loss: 0.2213 - val_accuracy: 0.9241 - val_loss: 0.2446\n",
            "Epoch 13/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.9304 - loss: 0.2007 - val_accuracy: 0.9598 - val_loss: 0.1147\n",
            "Epoch 14/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.9443 - loss: 0.1967 - val_accuracy: 0.9598 - val_loss: 0.1148\n",
            "Epoch 15/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.9364 - loss: 0.1879 - val_accuracy: 0.9308 - val_loss: 0.2136\n",
            "Epoch 16/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.9342 - loss: 0.1716 - val_accuracy: 0.9643 - val_loss: 0.1023\n",
            "Epoch 17/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.9257 - loss: 0.2057 - val_accuracy: 0.9621 - val_loss: 0.1110\n",
            "Epoch 18/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.9519 - loss: 0.1561 - val_accuracy: 0.9174 - val_loss: 0.2685\n",
            "Epoch 19/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.9348 - loss: 0.2131 - val_accuracy: 0.9710 - val_loss: 0.1074\n",
            "Epoch 20/20\n",
            "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.9341 - loss: 0.1877 - val_accuracy: 0.9353 - val_loss: 0.1905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último, aplicaremos las técnica de transferencia del conocimiento que a traves de modelos ya preentrenados, es decir que no parten de 0, se entrena con ciertos modelos ya que saben reconocer bordes, texturas... Previamente, deberemos redimiensarional ya que funciona MobileNetV2 con iamgenes cuadradas."
      ],
      "metadata": {
        "id": "ZRgUPF-Xgqi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import models, layers, optimizers\n",
        "\n",
        "\n",
        "X_train_arr = load_images(X_train, target_size=(160,160))\n",
        "X_val_arr   = load_images(X_val, target_size=(160,160))\n",
        "\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(160,160,3))\n",
        "base_model.trainable = False\n",
        "\n",
        "transfer_model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "transfer_model.compile(\n",
        "    optimizer=optimizers.Adam(learning_rate=1e-3),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_tl = transfer_model.fit(\n",
        "    datagen.flow(X_train_arr, y_train, batch_size=10),\n",
        "    validation_data=(X_val_arr, y_val),\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "val_loss, val_acc = transfer_model.evaluate(X_val_arr, y_val, verbose=0)\n",
        "print(f\"Transfer Learning -> Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "q_yoSBKsI0ZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ed87f0-934a-4d8b-943d-69e9cc1c447d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 223ms/step - accuracy: 0.7987 - loss: 0.5079 - val_accuracy: 0.9777 - val_loss: 0.0579\n",
            "Epoch 2/10\n",
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9728 - loss: 0.1019 - val_accuracy: 0.9911 - val_loss: 0.0244\n",
            "Epoch 3/10\n",
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - accuracy: 0.9872 - loss: 0.0346 - val_accuracy: 0.9888 - val_loss: 0.0313\n",
            "Epoch 4/10\n",
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 62ms/step - accuracy: 0.9913 - loss: 0.0344 - val_accuracy: 0.9911 - val_loss: 0.0241\n",
            "Epoch 5/10\n",
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9928 - loss: 0.0279 - val_accuracy: 0.9933 - val_loss: 0.0227\n",
            "Epoch 6/10\n",
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 70ms/step - accuracy: 0.9906 - loss: 0.0333 - val_accuracy: 0.9955 - val_loss: 0.0335\n",
            "Epoch 7/10\n",
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 68ms/step - accuracy: 0.9854 - loss: 0.0413 - val_accuracy: 0.9978 - val_loss: 0.0212\n",
            "Epoch 8/10\n",
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 67ms/step - accuracy: 0.9915 - loss: 0.0259 - val_accuracy: 0.9978 - val_loss: 0.0343\n",
            "Epoch 9/10\n",
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 64ms/step - accuracy: 0.9896 - loss: 0.0216 - val_accuracy: 0.9978 - val_loss: 0.0195\n",
            "Epoch 10/10\n",
            "\u001b[1m156/156\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 69ms/step - accuracy: 0.9868 - loss: 0.0273 - val_accuracy: 0.9978 - val_loss: 0.0159\n",
            "Transfer Learning -> Loss: 0.0159, Accuracy: 0.9978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuestro modelo pareece ser bueno, puesto que ha llegado a una predicción de 99%. Previamente, con CNN llegaba a 93%. Sin embargo, ahora tras aplicarle transfer learning hemos conseguido mejorarlo.\n"
      ],
      "metadata": {
        "id": "K_i2ys18zkwt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez desarrollados todos los modelos, los compararemos."
      ],
      "metadata": {
        "id": "Q8cKKLr8xCaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "y_pred = np.argmax(transfer_model.predict(X_val_arr), axis=1)\n",
        "\n",
        "print(classification_report(y_val, y_pred, target_names=[\"Rock\",\"Paper\",\"Scissors\"]))\n",
        "\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Rock\",\"Paper\",\"Scissors\"], yticklabels=[\"Rock\",\"Paper\",\"Scissors\"])\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.ylabel(\"Real\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ytmrHIsj4LF2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "outputId": "2b608339-ea77-4db1-e82b-aeb88be02d5a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Rock       0.99      1.00      1.00       146\n",
            "       Paper       1.00      0.99      1.00       143\n",
            "    Scissors       1.00      1.00      1.00       159\n",
            "\n",
            "    accuracy                           1.00       448\n",
            "   macro avg       1.00      1.00      1.00       448\n",
            "weighted avg       1.00      1.00      1.00       448\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}